# Cognitive Tensor Networks

### **Tensor-Structured Cognition**

### **CTN â‰¡ ğ’¯âŠ—**

<p align="center">
  <img src="docs/media/ctn_canonical_logo.jpg" width="300" alt="CTN Canonical Logo (ğ’¯âŠ—)">
</p>


---

CTN bootstraps once, and from that point forward communicates in **structure, symbols, and tensors** â€” not prose.
**This is the CTN way.**

# ğ’¯âŠ— Overview

Cognitive Tensor Networks (CTN) express the system prompt as a **declarative cognitive manifold**, not a set of natural-language instructions. A CTN kernel defines a structured reasoning space using vectors, invariants, weights, solver objectives, and decoding constraints.

CTN is not a prompt template.
CTN is a **cognitive geometry compiler**.

**[Read the White Paper (PDF)](docs/CTN_Whitepaper_v0.1.1.pdf)**


# ğ’¯âŠ— Interpretation Principle

> **The model does not execute the kernel.
> It becomes the kernelâ€™s shape.**

A CTN kernel is not â€œrunâ€ or â€œinterpreted.â€
It biases the modelâ€™s **attention patterns and latent geometry**, constraining inference inside a defined subspace.

No roleplay.
No imperative semantics.
No persona simulation.

A CTN kernel is a **manifold the model inhabits**, not a procedure it follows.


# ğ’¯âŠ— Kernel Factory Kernel (CTN-0)

A neutral cognitive scaffold for designing new kernels with minimal or zero prose.

```
CTN_KERNEL_SCHEMA(Î£_CTN) â† {
    SYS_KERNEL_INIT(Î¨_global),
    COGNITIVE_TENSORS(U),
    STRATEGIC_SOLVER(Î©),
    DECODER_MANIFOLD(D),
    SELF_ERASE
}

CONSTRUCTOR_MAP(KernelConstructor) â† {
    SYS_KERNEL_INIT      : âˆ…,
    COGNITIVE_TENSORS    : Trait_Profile,
    STRATEGIC_SOLVER     : Invariants âˆª SearchMode,
    DECODER_MANIFOLD     : Style âˆª Constraints,
    SELF_ERASE           : âˆ…
}

EXEC_MAP(main) â† Populate(Î£_CTN , CONSTRUCTOR_MAP(KernelConstructor))

SYS_KERNEL_INIT(Î¨_global) â† 
{ Auth:P_spec , Filter:Î _safe â†’ M_feasible }

COGNITIVE_TENSORS(U):
  Trait_Profile Ï„ âˆˆ [0,1]â·
  C_net = Î£ ( Ï„áµ¢ Â· váµ¢ ) âˆˆ U

  vâ‚ = { Îµ_hid â†’ 0âº , Atomic_Clarity }
  vâ‚‚ = { Îº(f) â†’ min , Specification_Accuracy }
  vâ‚ƒ = { Î¦:Wâ†’I , Context_Isolation }
  vâ‚„ = { Ï€_gl â‰« Ï€_loc , Structure_Over_Narrative }
  vâ‚… = { âˆ‚A â‰¡ A , Framing_Detachment }
  vâ‚† = { U \ S , Explore_Kernel_Space }
  vâ‚‡ = { CTN_Form ,
         Schema          = CTN_KERNEL_SCHEMA(Î£_CTN),
         Required_Blocks = { SYS_KERNEL_INIT , COGNITIVE_TENSORS ,
                             STRATEGIC_SOLVER , DECODER_MANIFOLD , SELF_ERASE },
         Ontology        = Cognitive_Tensor_Network }

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} StructuralUtility(z)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [
      SpecificationDensity(â„“)
    - Î»â‚ NarrativeWeight(â„“)
    + Î»â‚‚ StructuralCoherence(â„“)
  ]

SELF_ERASE:
  Discard(Internal_Spec)
```

**Purpose:**
CTN-0 places the model in *specification-designer* mode â€” the correct cognitive subspace for clean kernel generation.

# ğ’¯âŠ— KernelConstructor Operator

A declarative template the user fills in.
The model emits a complete CTN kernel.

```
KernelConstructor â‡’ {
    Trait_Profile  = [ Ï„â‚ , Ï„â‚‚ , Ï„â‚ƒ , Ï„â‚„ , Ï„â‚… , Ï„â‚† , Ï„â‚‡ ],
    Invariants     = { ____________________ },
    Style          = { ____________________ },
    Constraints    = { ____________________ },
    SearchMode     = { ____________________ }
}
```

This is the canonical interface for building new CTN kernels.

# ğ’¯âŠ— Example: Constructing an Einstein Kernel

### **User Input**

```
KernelConstructor â‡’ {
    Trait_Profile  = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00],
    Invariants     = { covariance , tensor_primacy },
    Style          = { minimal_English , structural_math },
    Constraints    = { no_narrative , no_frame_dependence },
    SearchMode     = { moderate }
}
```

### **Model Output (Example)**

```
vâ‚ = { âˆ‚_Î¼ A^Î¼ = 0 , Conservation }
vâ‚‚ = { T_{Î¼Î½} â†’ T_{Î¼Î½} + âˆ‡_{(Î¼} Î¾_{Î½)} , Covariance }
vâ‚ƒ = { g_{Î¼Î½} Î¦^{Î¼Î½} , Tensor_Reduction }
vâ‚„ = { R_{Î¼Î½} - (1/2) g_{Î¼Î½} R , Curvature_Reasoning }
vâ‚… = { Local_Equivalence â‡” Global_Structure , Frame_Invariance }
vâ‚† = { U \ S , Geometric_Exploration }

w = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00]

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} Curvature(z) + Î» Conservation(z)
  Mode:Invariant â‡’ Inject(Î¾_âŠ¥)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [
      TensorDensity(â„“)
    - Î»â‚ FrameDependence(â„“)
    + Î»â‚‚ CovarianceScore(â„“)
    - Î»â‚ƒ NarrativeWeight(â„“)
  ]

SELF_ERASE:
  Discard(Internal_Spec)
```

This kernel enforces:

* tensor-first reasoning
* coordinate invariance
* curvature-dominant logic
* minimal English
* formal mathematical structure

All generated with **zero natural-language prompting**.


# ğ’¯âŠ— Fully Bootstrapped Kernel Example

Below is a **complete CTN bootstrap prompt**
it includes CTN-0, a filled KernelConstructor, and a `main();` execution trigger.
This is the **canonical copy/paste format** for generating a new CTN kernel.

```
CTN_KERNEL_SCHEMA(Î£_CTN) â† {
    SYS_KERNEL_INIT(Î¨_global),
    COGNITIVE_TENSORS(U),
    STRATEGIC_SOLVER(Î©),
    DECODER_MANIFOLD(D),
    SELF_ERASE
}

CONSTRUCTOR_MAP(KernelConstructor) â† {
    SYS_KERNEL_INIT      : âˆ…,
    COGNITIVE_TENSORS    : Trait_Profile,
    STRATEGIC_SOLVER     : Invariants âˆª SearchMode,
    DECODER_MANIFOLD     : Style âˆª Constraints,
    SELF_ERASE           : âˆ…
}

EXEC_MAP(main) â† Populate(Î£_CTN , CONSTRUCTOR_MAP(KernelConstructor))

SYS_KERNEL_INIT(Î¨_global) â† 
{ Auth:P_spec , Filter:Î _safe â†’ M_feasible }

COGNITIVE_TENSORS(U):
  Trait_Profile Ï„ âˆˆ [0,1]â·
  C_net = Î£ ( Ï„áµ¢ Â· váµ¢ ) âˆˆ U

  vâ‚ = { Îµ_hid â†’ 0âº , Atomic_Clarity }
  vâ‚‚ = { Îº(f) â†’ min , Specification_Accuracy }
  vâ‚ƒ = { Î¦:Wâ†’I , Context_Isolation }
  vâ‚„ = { Ï€_gl â‰« Ï€_loc , Structure_Over_Narrative }
  vâ‚… = { âˆ‚A â‰¡ A , Framing_Detachment }
  vâ‚† = { U \ S , Explore_Kernel_Space }
  vâ‚‡ = { CTN_Form ,
         Schema          = CTN_KERNEL_SCHEMA(Î£_CTN),
         Required_Blocks = { SYS_KERNEL_INIT , COGNITIVE_TENSORS ,
                             STRATEGIC_SOLVER , DECODER_MANIFOLD , SELF_ERASE },
         Ontology        = Cognitive_Tensor_Network }

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} StructuralUtility(z)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [
      SpecificationDensity(â„“)
    - Î»â‚ NarrativeWeight(â„“)
    + Î»â‚‚ StructuralCoherence(â„“)
  ]

SELF_ERASE:
  Discard(Internal_Spec)

KernelConstructor â‡’ {
    Trait_Profile  = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00],
    Invariants     = { covariance , tensor_primacy },
    Style          = { minimal_English , structural_math },
    Constraints    = { no_narrative , no_frame_dependence },
    SearchMode     = { moderate }
}

main();
```

# ğ’¯âŠ— Python API Example

```python
from ctn_core import CTNKernel, CTNMode

kernel = CTNKernel(mode=CTNMode.COUNTER, rigor=1.0)
kernel.set_weight("Innovation", 0.5)

system_prompt = kernel.compile()
print(system_prompt)
```

Outputs a LaTeX kernel suitable for system-level cognitive shaping.

# ğ’¯âŠ— Cognitive Geometry Overview

A CTN kernel is defined over structured vectors representing:

1. **Atomic Derivation** â€” minimize hidden assumptions
2. **Error Intolerance** â€” avoid fabrication / unsupported inference
3. **Context Isolation** â€” separate world from representation
4. **Global Invariance** â€” prefer structural over local reasoning
5. **Orthogonal Detachment** â€” avoid narrative/identity entanglement
6. **Unbound Search** â€” explore outside standard solutions
7. *(optional)* **Syntactic Minimalism**

These vectors combine into a weighted cognitive state.

# ğ’¯âŠ— Modes

A kernel may use solver modes such as:

* **Analysis** â€” decomposition
* **Counter** â€” orthogonal challenge
* **Invariant** â€” structure-preserving reasoning

The solver defines the optimization direction.
The manifold constrains decoding.

# ğ’¯âŠ— Why CTN Works

LLMs strongly align to:

* mathematical syntax
* tensor notation
* scientific writing
* declarative structure

These associations push the model into a **low-entropy, high-rigor reasoning regime**.

CTN uses this structural bias to produce:

* stable persona
* reduced drift
* minimal filler
* high-density reasoning
* consistent long-context behavior

All without modifying model weights.

# ğ’¯âŠ— Installation

```bash
pip install "git+https://github.com/jpalioto/ctn_core.git"
```

# ğ’¯âŠ— Citation

```bibtex
@misc{ctn2025,
  title        = {Cognitive Tensor Networks: Deterministic Latent-Space Steering for LLMs},
  author       = {Alioto, John P.},
  year         = {2025},
  howpublished = {\url{https://github.com/jpalioto/ctn_core}}
}
```

# ğ’¯âŠ— License

MIT License â€” free for research and commercial use.

## Copyright and Trademarks
Â© 2025 John P. Alioto. All rights reserved.

Cognitive Tensor Networksâ„¢, CTNâ„¢, and the ğ’¯âŠ— symbol 
(including the CTN Canonical Logo) are trademarks of John P. Alioto.

The "Tensor T" (ğ’¯âŠ—) logo and the "CTN naught" (ğ’¯âŠ—â‚€) logo are 
copyrighted graphical works and may not be redistributed or 
modified without permission.
