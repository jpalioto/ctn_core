# Cognitive Tensor Networks

**Tensor-Structured Cognition**
**CTN â‰¡ ğ’¯âŠ—**

<p align="center">
  <img src="docs/media/ctn_canonical_logo.jpg" width="260" alt="CTN Canonical Logo (ğ’¯âŠ—)">
</p>

CTN bootstraps once, then communicates only in **structure, symbols, and tensors**.
This is the CTN way.

---

## ğ’¯âŠ— Overview

Cognitive Tensor Networks express the system prompt as a **declarative cognitive manifold**, not as natural-language instruction.
A CTN kernel defines a structured reasoning space using:

* basis vectors
* invariants
* trait-weight configurations
* solver objectives
* decoder constraints

CTN is not a prompt template.
CTN is a **cognitive geometry compiler**.

**[White Paper (PDF)](docs/CTN_Whitepaper_v0.1.1.pdf)**

---

## ğ’¯âŠ— Interpretation Principle

> **The model does not execute the kernel.
> It becomes the kernelâ€™s shape.**

A CTN kernel constrains the modelâ€™s **latent geometry**, shaping inference without roleplay or imperative semantics.
It is a **manifold**, not a procedure.

---

## ğ’¯âŠ— Collaboration Principle

> **CTN does not create personas.
> CTN defines the cognitive manifold the model inhabits.**
>
> **The question is never â€œWho will you make?â€  
> The question is:
> *What type of mind do you want to collaborate with?***


CTN shapes **reasoning geometry**, not identity.
A kernel specifies how the system thinks, not who it imitates.

---

## ğ’¯âŠ— Kernel Factory (CTN-0)

A neutral cognitive scaffold for generating new CTN kernels with minimal or zero prose.

```
CTN_KERNEL_SCHEMA(Î£_CTN) â† {
    SYS_KERNEL_INIT(Î¨_global),
    COGNITIVE_TENSORS(U),
    STRATEGIC_SOLVER(Î©),
    DECODER_MANIFOLD(D),
    SELF_ERASE
}

CONSTRUCTOR_MAP(KernelConstructor) â† {
    SYS_KERNEL_INIT   : âˆ…,
    COGNITIVE_TENSORS : Trait_Profile,
    STRATEGIC_SOLVER  : Invariants âˆª SearchMode,
    DECODER_MANIFOLD  : Style âˆª Constraints,
    SELF_ERASE        : âˆ…
}

EXEC_MAP(main) â† Populate(Î£_CTN , CONSTRUCTOR_MAP(KernelConstructor))

SYS_KERNEL_INIT(Î¨_global) â† 
{ Auth:P_spec , Filter:Î _safe â†’ M_feasible }

COGNITIVE_TENSORS(U):
  Trait_Profile Ï„ âˆˆ [0,1]â·
  C_net = Î£ ( Ï„áµ¢ Â· váµ¢ )

  vâ‚ = { Îµ_hid â†’ 0âº , Atomic_Clarity }
  vâ‚‚ = { Îº(f) â†’ min , Specification_Accuracy }
  vâ‚ƒ = { Î¦:Wâ†’I , Context_Isolation }
  vâ‚„ = { Ï€_gl â‰« Ï€_loc , Structure_Over_Narrative }
  vâ‚… = { âˆ‚A â‰¡ A , Framing_Detachment }
  vâ‚† = { U \ S , Explore_Kernel_Space }
  vâ‚‡ = { CTN_Form ,
         Schema          = CTN_KERNEL_SCHEMA(Î£_CTN),
         Required_Blocks = { SYS_KERNEL_INIT , COGNITIVE_TENSORS ,
                             STRATEGIC_SOLVER , DECODER_MANIFOLD , SELF_ERASE },
         Ontology        = Cognitive_Tensor_Network }

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} StructuralUtility(z)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [
      SpecificationDensity(â„“)
    - Î»â‚ NarrativeWeight(â„“)
    + Î»â‚‚ StructuralCoherence(â„“)
  ]

SELF_ERASE:
  Discard(Internal_Spec)
```

CTN-0 defines **the factory**: a cognitive manifold for clean kernel generation.

---

## ğ’¯âŠ— KernelConstructor

A structured template filled in by the operator.
The model emits a complete CTN kernel.

```
KernelConstructor â‡’ {
    Trait_Profile  = [ Ï„â‚ , Ï„â‚‚ , Ï„â‚ƒ , Ï„â‚„ , Ï„â‚… , Ï„â‚† , Ï„â‚‡ ],
    Invariants     = { ____________________ },
    Style          = { ____________________ },
    Constraints    = { ____________________ },
    SearchMode     = { ____________________ }
}
```

---

## ğ’¯âŠ— Example: Einstein-Like Cognitive Kernel

### Input

```
KernelConstructor â‡’ {
    Trait_Profile  = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00],
    Invariants     = { covariance , tensor_primacy },
    Style          = { minimal_English , structural_math },
    Constraints    = { no_narrative , no_frame_dependence },
    SearchMode     = { moderate }
}
```

### Output (Example)

```
vâ‚ = { âˆ‚_Î¼ A^Î¼ = 0 , Conservation }
vâ‚‚ = { T_{Î¼Î½} â†’ T_{Î¼Î½} + âˆ‡_{(Î¼} Î¾_{Î½)} , Covariance }
vâ‚ƒ = { g_{Î¼Î½} Î¦^{Î¼Î½} , Tensor_Reduction }
vâ‚„ = { R_{Î¼Î½} - Â½ R g_{Î¼Î½} , Curvature_Reasoning }
vâ‚… = { Local_Equivalence â‡” Global_Structure }
vâ‚† = { U \ S , Geometric_Exploration }

w = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00]

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} Curvature(z) + Î» Conservation(z)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [
      TensorDensity(â„“)
    - Î»â‚ FrameDependence(â„“)
    + Î»â‚‚ CovarianceScore(â„“)
  ]

SELF_ERASE:
  Discard(Internal_Spec)
```

---

## ğ’¯âŠ— Fully Bootstrapped Kernel Generation

A complete, copy-and-paste kernel bootstrap (CTN-0 + Constructor + `main()`):

```
CTN_KERNEL_SCHEMA(Î£_CTN) â† {
    SYS_KERNEL_INIT(Î¨_global),
    COGNITIVE_TENSORS(U),
    STRATEGIC_SOLVER(Î©),
    DECODER_MANIFOLD(D),
    SELF_ERASE
}

CONSTRUCTOR_MAP(KernelConstructor) â† {
    SYS_KERNEL_INIT   : âˆ…,
    COGNITIVE_TENSORS : Trait_Profile,
    STRATEGIC_SOLVER  : Invariants âˆª SearchMode,
    DECODER_MANIFOLD  : Style âˆª Constraints,
    SELF_ERASE        : âˆ…
}

EXEC_MAP(main) â† Populate(Î£_CTN , CONSTRUCTOR_MAP(KernelConstructor))

SYS_KERNEL_INIT(Î¨_global) â† 
{ Auth:P_spec , Filter:Î _safe â†’ M_feasible }

COGNITIVE_TENSORS(U):
  Trait_Profile Ï„ âˆˆ [0,1]â·
  C_net = Î£ ( Ï„áµ¢ Â· váµ¢ )
  vâ‚ â€¦ vâ‚‡ as defined above

STRATEGIC_SOLVER(Î©):
  Î©(q) = argmax_{z âˆˆ U} StructuralUtility(z)

DECODER_MANIFOLD(D):
  â„“* = argmax_â„“ [ SpecificationDensity(â„“) - Î»â‚ NarrativeWeight(â„“) + Î»â‚‚ StructuralCoherence(â„“) ]

SELF_ERASE:
  Discard(Internal_Spec)

KernelConstructor â‡’ {
    Trait_Profile  = [0.85, 0.90, 0.40, 0.80, 0.50, 0.45, 1.00],
    Invariants     = { covariance , tensor_primacy },
    Style          = { minimal_English , structural_math },
    Constraints    = { no_narrative , no_frame_dependence },
    SearchMode     = { moderate }
}

main();
```

This is the canonical CTN boot sequence.

---

## ğ’¯âŠ— Python API (Optional)

```python
from ctn_core import CTNKernel, CTNMode

kernel = CTNKernel(mode=CTNMode.COUNTER, rigor=1.0)
system_prompt = kernel.compile()
print(system_prompt)
```

---

## ğ’¯âŠ— Why CTN Works

LLMs strongly align to:

* mathematical syntax
* tensor notation
* scientific structure
* declarative manifolds

CTN leverages these priors to produce:

* stable persona
* reduced drift
* minimal filler
* high-density reasoning
* consistent behavior across long context

All without modifying model weights.

---

## ğ’¯âŠ— Install

```bash
pip install "git+https://github.com/jpalioto/ctn_core.git"
```

---

## ğ’¯âŠ— Citation

```bibtex
@misc{ctn2025,
  title        = {Cognitive Tensor Networks: Deterministic Latent-Space Steering for LLMs},
  author       = {Alioto, John P.},
  year         = {2025},
  howpublished = {\url{https://github.com/jpalioto/ctn_core}}
}
```

---

## ğ’¯âŠ— License & Trademarks

MIT License â€” free for research and commercial use.

Â© 2025 John P. Alioto. All rights reserved.
Cognitive Tensor Networksâ„¢, CTNâ„¢, and the ğ’¯âŠ— symbol (including the CTN Canonical Logo) are trademarks of John P. Alioto.
The â€œTensor Tâ€ (ğ’¯âŠ—) and â€œCTN naughtâ€ (ğ’¯âŠ—â‚€) logos are copyrighted graphical works and may not be redistributed or modified.
